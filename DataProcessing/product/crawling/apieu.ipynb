{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs              # 데이터파싱 라이브러리\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from threading import Thread\n",
    "import json\n",
    "import platform\n",
    "import re\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'chromedriver.exe' if (platform.system() == 'Windows') else '/Users/jg/Desktop/develop/DataTeam/DataProcessing/product/crawling/chromedriver';\n",
    "driver = webdriver.Chrome(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeJSON(jsonString, output_name='data.json'):\n",
    "    with open(output_name,'w',encoding='UTF-8') as file:\n",
    "        file.write(jsonString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorys = [115015010000]\n",
    "categorys = [115015007000, 115015008000, 115015017000, 115015015000, 115015014000, 115015009000, 115015010000, 120000000328, 120000000333, 115015013000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUrlList():\n",
    "    urlList = []\n",
    "    for category in categorys:\n",
    "        #카테고리별로 접속\n",
    "        driver.get(\"http://apieu.beautynet.co.kr/goods.list.do?upperDisplayCategoryNumber=\" + str(category) + \"&displayCategoryNumber=0\")\n",
    "        \n",
    "        #상품 긁기\n",
    "        while True:\n",
    "            html = driver.page_source\n",
    "            soup = bs(html,'html.parser')\n",
    "            products = driver.find_elements_by_xpath(\"//p[@class='pname']//a\")\n",
    "            for product in products:\n",
    "                urlList.append(product.get_attribute(\"href\"))\n",
    "            try:\n",
    "                driver.find_element_by_xpath(\"//a[@class='nextBtn']\").click()\n",
    "            except NoSuchElementException:\n",
    "                break;\n",
    "    return urlList\n",
    "        \n",
    "        #다음 페이지가 있으면 다음 페이지로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlList = getUrlList()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1213\n"
     ]
    }
   ],
   "source": [
    "urlList = list(set(urlList))\n",
    "print(len(urlList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getItemDetailByUrl(urlList):\n",
    "    result_json = []\n",
    "    for idx, item in enumerate(urlList):\n",
    "        driver.get(item)\n",
    "        html = driver.page_source\n",
    "        soup = bs(html,'html.parser')\n",
    "        # dictionary 생성\n",
    "        result = {'name':'', 'url':'', 'image':'', 'salePrice':'', 'originalPrice':'', 'color':'', \n",
    "                   'category':'', 'brand':'어퓨','volume':''}\n",
    "        \n",
    "        fullName = soup.find('h2',{'id':'goodsProdName'}).get_text().strip('[어퓨]')\n",
    "        checkContainsColor = fullName.find('[')\n",
    "        if checkContainsColor == -1:\n",
    "            result['name'] = fullName\n",
    "            result['color'] = \"#\"\n",
    "        else:\n",
    "            result['name'] = fullName[:checkContainsColor]\n",
    "            result['color'] = fullName[checkContainsColor + 1: len(fullName)]\n",
    "        \n",
    "        result['url'] = driver.current_url\n",
    "        categorys = []\n",
    "        findCategory = soup.find('div',{'class':'tit_path'}).find_all('li')\n",
    "        for category in findCategory:\n",
    "            categorys.append(category.get_text().strip('\\n'))\n",
    "        result['category'] = '>'.join(categorys)\n",
    "        \n",
    "        #컬러가 있는지 체크\n",
    "#         if soup.find('div', {'class':'colorList'}) is None:\n",
    "            #단품\n",
    "        images = driver.find_elements_by_xpath(\"//ul[@class='simg']//li//a//img\")\n",
    "        result['image'] = [image.get_attribute('src') for image in images]\n",
    "        result['salePrice'] = soup.find('div',{'class':'itemBox priceInfo'}).find('span',{'class':'price'}).get_text()\n",
    "        result['originalPrice'] = result['salePrice'] if soup.find('div',{'class':'itemBox priceInfo'}).find('span',{'class':'fixedPrice'}) is None else soup.find('div',{'class':'itemBox priceInfo'}).find('span',{'class':'fixedPrice'}).get_text()\n",
    "        infoOptions = soup.find('div',{'class':'itemBox dtlInfo'}).find_all('dl')\n",
    "        for option in infoOptions:\n",
    "            if option.dt.get_text() == \"용량\":\n",
    "                result['volume'] = option.dd.get_text()\n",
    "                break;\n",
    "        \n",
    "        #display(result)\n",
    "        result_json.append(result)\n",
    "#         else:\n",
    "#             #컬러 있음\n",
    "#             #Check # of Colors\n",
    "#             colorList = driver.find_elements_by_xpath(\"//div[@class='bx-viewport']//li\")\n",
    "#             for idx, color in enumerate(colorList):\n",
    "#                 color.click()\n",
    "#                 result_dict = copy.deepcopy(result)\n",
    "#                 images = driver.find_elements_by_xpath(\"//ul[@class='simg']//li//a//img\")\n",
    "#                 result_dict['image'] = [image.get_attribute('src') for image in images]\n",
    "#                 result_dict['salePrice'] = soup.find('div',{'class':'itemBox priceInfo'}).find('span',{'class':'price'}).get_text()\n",
    "#                 result_dict['originalPrice'] = result_dict['salePrice'] if soup.find('div',{'class':'itemBox priceInfo'}).find('span',{'class':'fixedPrice'}) is None else soup.find('div',{'class':'itemBox priceInfo'}).find('span',{'class':'fixedPrice'}).get_text()\n",
    "#                 infoOptions = soup.find('div',{'class':'itemBox dtlInfo'}).find_all('dl')\n",
    "#                 for option in infoOptions:\n",
    "#                     if option.dt.get_text() == \"용량\":\n",
    "#                         result_dict['volume'] = option.dd.get_text()\n",
    "#                         break;\n",
    "#                 result_dict['color'] = color.find_element_by_tag_name('a').get_attribute('data-option_goods_name')\n",
    "#                 result_json.append(result_dict)\n",
    "#                 display(result_dict)\n",
    "        if idx % (len(urlList)//50) == 0:\n",
    "            print(\"%3.1f 퍼센트 진행중\" % round(idx / len(urlList) * 100))\n",
    "    return result_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 퍼센트 진행중\n",
      "2.0 퍼센트 진행중\n",
      "4.0 퍼센트 진행중\n",
      "6.0 퍼센트 진행중\n",
      "8.0 퍼센트 진행중\n",
      "10.0 퍼센트 진행중\n",
      "12.0 퍼센트 진행중\n",
      "14.0 퍼센트 진행중\n",
      "16.0 퍼센트 진행중\n",
      "18.0 퍼센트 진행중\n",
      "20.0 퍼센트 진행중\n",
      "22.0 퍼센트 진행중\n",
      "24.0 퍼센트 진행중\n",
      "26.0 퍼센트 진행중\n",
      "28.0 퍼센트 진행중\n",
      "30.0 퍼센트 진행중\n",
      "32.0 퍼센트 진행중\n",
      "34.0 퍼센트 진행중\n",
      "36.0 퍼센트 진행중\n",
      "38.0 퍼센트 진행중\n",
      "40.0 퍼센트 진행중\n",
      "42.0 퍼센트 진행중\n",
      "44.0 퍼센트 진행중\n",
      "46.0 퍼센트 진행중\n",
      "47.0 퍼센트 진행중\n",
      "49.0 퍼센트 진행중\n",
      "51.0 퍼센트 진행중\n",
      "53.0 퍼센트 진행중\n",
      "55.0 퍼센트 진행중\n",
      "57.0 퍼센트 진행중\n",
      "59.0 퍼센트 진행중\n",
      "61.0 퍼센트 진행중\n",
      "63.0 퍼센트 진행중\n",
      "65.0 퍼센트 진행중\n",
      "67.0 퍼센트 진행중\n",
      "69.0 퍼센트 진행중\n",
      "71.0 퍼센트 진행중\n",
      "73.0 퍼센트 진행중\n",
      "75.0 퍼센트 진행중\n",
      "77.0 퍼센트 진행중\n",
      "79.0 퍼센트 진행중\n",
      "81.0 퍼센트 진행중\n",
      "83.0 퍼센트 진행중\n",
      "85.0 퍼센트 진행중\n",
      "87.0 퍼센트 진행중\n",
      "89.0 퍼센트 진행중\n",
      "91.0 퍼센트 진행중\n",
      "93.0 퍼센트 진행중\n",
      "95.0 퍼센트 진행중\n",
      "97.0 퍼센트 진행중\n",
      "99.0 퍼센트 진행중\n"
     ]
    }
   ],
   "source": [
    "result_json = getItemDetailByUrl(urlList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = json.dumps(result_json,ensure_ascii=False, indent='\\t')\n",
    "\n",
    "writeJSON(output, output_name = 'apieu.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
